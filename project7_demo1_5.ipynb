{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elenaporras-mx/Project7_AI/blob/main/project7_demo1_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C_7eSorXiX2"
      },
      "source": [
        "# ðŸ¤– AlphaZero-Style MCTS: Play Tic-Tac-Toe vs. the Agent\n",
        "This notebook lets you play as 'O' against an AlphaZero-style MCTS agent playing 'X'.\n",
        "- Agent uses a fake neural net (priors + value) to guide tree search.\n",
        "- You choose moves using input().\n",
        "- Board updates every turn until the game ends.\n"
      ],
      "id": "9C_7eSorXiX2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **What to Watch:** Weâ€™ll visualize how the performance of the agent improves over training iterations. Early on, it plays randomly. After a few iterations of self-play and training, youâ€™ll see the agent start to prefer stronger moves (as identified by the combination of its network and search). We can plot the win-rate of the agent against an earlier version of itself over training time â€“ you should see it climbing.\n",
        "- **Outcome:** By the end of the demo training, the agent should play the game at a competent level (possibly perfectly if the game is simple like Tic-Tac-Toe). This will mirror, in miniature, the process AlphaZero underwent â€“ though of course our demo is far smaller in scale.\n",
        "- **Key Point:** Even in this small example, using MCTS to assist learning can dramatically accelerate the learning of the network, compared to learning the game solely by policy gradient or value iteration without lookahead."
      ],
      "metadata": {
        "id": "TssrqP0tCUKx"
      },
      "id": "TssrqP0tCUKx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHXfovMUXiX3"
      },
      "outputs": [],
      "source": [
        "# === game & mcts definitions ===\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class TicTacToe:\n",
        "   def __init__(self):\n",
        "       self.board = [' '] * 9  # create empty 3x3 board\n",
        "       self.current_player = 'X'  # x goes first\n",
        "\n",
        "   def legal_moves(self):\n",
        "       # return indexes of empty spaces\n",
        "       return [i for i in range(9) if self.board[i] == ' ']\n",
        "\n",
        "   def make_move(self, idx):\n",
        "       # try to place mark at position idx\n",
        "       if self.board[idx] == ' ':\n",
        "           self.board[idx] = self.current_player\n",
        "           self.current_player = 'O' if self.current_player == 'X' else 'X'  # swap players\n",
        "           return True\n",
        "       return False\n",
        "\n",
        "   def check_winner(self):\n",
        "       # all possible winning combinations\n",
        "       wins = [(0,1,2),(3,4,5),(6,7,8),(0,3,6),(1,4,7),(2,5,8),(0,4,8),(2,4,6)]\n",
        "       for a,b,c in wins:\n",
        "           if self.board[a] != ' ' and self.board[a] == self.board[b] == self.board[c]:\n",
        "               return self.board[a]  # return winning player\n",
        "       if ' ' not in self.board:\n",
        "           return 'Draw'\n",
        "       return None\n",
        "\n",
        "   def print_board(self):\n",
        "       # display board with separators\n",
        "       for i in range(0, 9, 3):\n",
        "           print(' | '.join(self.board[i:i+3]))\n",
        "           if i < 6:\n",
        "               print('--+---+--')"
      ],
      "id": "xHXfovMUXiX3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9Vza02dXiX4"
      },
      "outputs": [],
      "source": [
        "# === alphazero-style mcts ===\n",
        "class AZNode:\n",
        "    def __init__(self, state, parent=None, move=None, prior=1.0):\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.move = move\n",
        "        self.prior = prior  # probability from policy network\n",
        "        self.children = []\n",
        "        self.visits = 0\n",
        "        self.wins = 0\n",
        "\n",
        "    def uct_score(self, c=1.41):\n",
        "        # calculate exploration score with prior probability\n",
        "        if self.visits == 0:\n",
        "            return self.prior + 1e-8  # prevent division by zero\n",
        "        return (self.wins / self.visits) + c * self.prior * np.sqrt(np.log(self.parent.visits + 1) / self.visits)"
      ],
      "id": "T9Vza02dXiX4"
    },
    {
      "cell_type": "code",
      "source": [
        "def dummy_nn_prior_value(board):\n",
        "    # fake neural network giving uniform priors over legal moves\n",
        "    priors = {i: 1/9 for i in range(9) if board[i] == ' '}\n",
        "    return priors, 0.0"
      ],
      "metadata": {
        "id": "zbUBh8cH8VwQ"
      },
      "id": "zbUBh8cH8VwQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_random_game(start):\n",
        "    # play out a random game from given state\n",
        "    game = TicTacToe()\n",
        "    game.board = start.board[:]\n",
        "    game.current_player = start.current_player\n",
        "    while game.check_winner() is None:\n",
        "        move = np.random.choice(game.legal_moves())\n",
        "        game.make_move(move)\n",
        "    return game.check_winner()"
      ],
      "metadata": {
        "id": "EY-h_z_p8X7j"
      },
      "id": "EY-h_z_p8X7j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def az_mcts_search(root_state, sims=100):\n",
        "    # conduct monte carlo tree search with alphazero improvements\n",
        "    priors, _ = dummy_nn_prior_value(root_state.board)\n",
        "    root = AZNode(root_state, prior=1.0)\n",
        "    # initialize tree with all possible moves\n",
        "    for move, prior in priors.items():\n",
        "        g = TicTacToe()\n",
        "        g.board = root_state.board[:]\n",
        "        g.current_player = root_state.current_player\n",
        "        g.make_move(move)\n",
        "        root.children.append(AZNode(g, parent=root, move=move, prior=prior))\n",
        "\n",
        "    # run simulations\n",
        "    for _ in range(sims):\n",
        "        node = root\n",
        "        path = [node]\n",
        "        # selection phase - traverse tree using uct\n",
        "        while node.children:\n",
        "            node = max(node.children, key=lambda n: n.uct_score())\n",
        "            path.append(node)\n",
        "        # simulation and backpropagation\n",
        "        result = simulate_random_game(node.state)\n",
        "        for n in path:\n",
        "            n.visits += 1\n",
        "            if result == root_state.current_player:\n",
        "                n.wins += 1\n",
        "            elif result == 'Draw':\n",
        "                n.wins += 0.5\n",
        "    return root"
      ],
      "metadata": {
        "id": "G1ITGeY08ZIp"
      },
      "id": "G1ITGeY08ZIp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gj92Y5rXiX4",
        "outputId": "faa65ae8-09ed-41e4-9f56-7bd927c2bc15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Agent (X) moves:\n",
            "X |   |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "X |   |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "Your move (O). Choose one of these: [1, 2, 3, 4, 5, 6, 7, 8]\n",
            "Enter your move (0-8): 4\n",
            "You moved.\n",
            "\n",
            "Agent (X) moves:\n",
            "X | X |  \n",
            "--+---+--\n",
            "  | O |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "X | X |  \n",
            "--+---+--\n",
            "  | O |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "Your move (O). Choose one of these: [2, 3, 5, 6, 7, 8]\n",
            "Enter your move (0-8): 2\n",
            "You moved.\n",
            "\n",
            "Agent (X) moves:\n",
            "X | X | O\n",
            "--+---+--\n",
            "X | O |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "X | X | O\n",
            "--+---+--\n",
            "X | O |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "Your move (O). Choose one of these: [5, 6, 7, 8]\n",
            "Enter your move (0-8): 6\n",
            "You moved.\n",
            "X | X | O\n",
            "--+---+--\n",
            "X | O |  \n",
            "--+---+--\n",
            "O |   |  \n",
            "\n",
            "Game Over! Winner: O\n"
          ]
        }
      ],
      "source": [
        "# === gameplay loop ===\n",
        "game = TicTacToe()\n",
        "while game.check_winner() is None:\n",
        "    if game.current_player == 'X':\n",
        "        # ai makes a move\n",
        "        root = az_mcts_search(game, sims=100)\n",
        "        best = max(root.children, key=lambda c: c.visits)  # pick most visited move\n",
        "        game = best.state\n",
        "        print(\"\\nAgent (X) moves:\")\n",
        "        game.print_board()\n",
        "    else:\n",
        "        # human player's turn\n",
        "        game.print_board()\n",
        "        print(\"Your move (O). Choose one of these:\", game.legal_moves())\n",
        "        move = int(input(\"Enter your move (0-8): \"))\n",
        "        # validate input\n",
        "        while move not in game.legal_moves():\n",
        "            move = int(input(\"Invalid. Try again (0-8): \"))\n",
        "        game.make_move(move)\n",
        "        print(\"You moved.\")\n",
        "\n",
        "# game over\n",
        "winner = game.check_winner()\n",
        "game.print_board()\n",
        "print(\"\\nGame Over! Winner:\", winner)"
      ],
      "id": "7Gj92Y5rXiX4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}